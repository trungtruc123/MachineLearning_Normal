{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read file xlsx : select name img_err save file img_error.txt, dictionary save tọa độ of ảnh bị lôic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "lambda x: x*3\n",
    "a = lambda x: x+3\n",
    "print(a(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  age  text  xmax\n",
      "0   truc   12     0    23\n",
      "1  thanh   13     1    45\n",
      "2  trung   14     1    12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'name':['truc', 'thanh','trung'], 'age':[12,13,14], 'text':[0,1,1],'xmax':[23,45,12]}, columns=['name', 'age','text','xmax'])\n",
    "print(df)\n",
    "\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv('test.csv', s)\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: name    truc\n",
      "age       12\n",
      "text       0\n",
      "Name: 0, dtype: object\n",
      "row: name    thanh\n",
      "age        13\n",
      "text        1\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    print('row:',row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     truc\n",
      "1    thanh\n",
      "2    trung\n",
      "name_text1:     name\n",
      "1  thanh\n",
      "2  trung\n",
      "count name : 2\n"
     ]
    }
   ],
   "source": [
    "name = df['name']\n",
    "print(name.to_string())\n",
    "# print(name)\n",
    "name_text1 = df[df['text']==1][['name']]\n",
    "print('name_text1:', name_text1.to_string())\n",
    "print('count name :',len(name_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thanh\n",
      "trung\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = ''\n",
    "for i in range(df.shape[0]):\n",
    "    a = df.iloc[i,2]\n",
    "#     print(a)\n",
    "    if a==1:\n",
    "        string += df.iloc[i,0] +'\\n'\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('img_error.txt','w') as f:\n",
    "    f.write(string)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lấy tọa độ để cắt ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thanh': [13, 45], 'trung': [14, 12]}\n",
      "dict_keys(['thanh', 'trung'])\n",
      "OK\n",
      "thanh\n",
      "trung\n",
      "[13, 45]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "dict_coordinate ={}\n",
    "name =''\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    a = df.iloc[i,2]\n",
    "    if a==1:\n",
    "        name = df.iloc[i,0]\n",
    "        xmin = df.iloc[i,1]\n",
    "        xmax = df.iloc[i,3]\n",
    "        dict_coordinate[name] = [xmin,xmax]\n",
    "print(dict_coordinate)\n",
    "print(dict_coordinate.keys())\n",
    "for name in dict_coordinate.keys():\n",
    "    if name == 'thanh':\n",
    "        print('OK')\n",
    "    print(name)\n",
    "print(dict_coordinate['thanh'])\n",
    "print(dict_coordinate['thanh'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cắt ảnh không bị lỗi , label =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "string = ''\n",
    "for file_img in os.listdir('./data_text'):\n",
    "    string += file_img + '\\n'\n",
    "\n",
    "with open('img_normal.txt','w') as f:\n",
    "    f.write(string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cắt ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "path =''\n",
    "def crop (img,xmin,xmax,y_min,y_max):\n",
    "    image = cv2.imread(img)\n",
    "    img_cut = image[xmin:xmax, ymin:ymax]\n",
    "    cv2.imwrite(os.path.join('',img_cut)\n",
    "\n",
    "def crop_img():\n",
    "    for file in os.listdir('./data_text'):\n",
    "        img = os.path.join(path, file)\n",
    "#         image = cv2.imread(img)\n",
    "        for name in dict_coordinate.keys():\n",
    "            if name == file:\n",
    "                xmin = dict_coordinate[name][0]\n",
    "                xmax = dict_coordinate[name][1]\n",
    "                crop(img, xmin, xmax, y_min, y_max)\n",
    "                \n",
    "            \n",
    "# def crop(img):    \n",
    "#     image = cv2.imread(img)\n",
    "#     address = image[165:195,38:439]\n",
    "#     cv2.imwrite('image_cut/cut.png',address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Làm mượt ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "def processing(img):\n",
    "    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "    print(image.shape)\n",
    "    blur = cv2.bilateralFilter(image, 5, 75, 75)\n",
    "    img_binary = cv2.adaptiveThreshold(blur, \n",
    "                                       maxValue=255, \n",
    "                                       adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                       thresholdType=cv2.THRESH_BINARY,\n",
    "                                       blockSize=11,\n",
    "                                       C=6)\n",
    "    blur_next = cv2.GaussianBlur(img_binary,(3,3),0)\n",
    "    imgScale = cv2.resize(blur_next, (int(1280), int(64)), interpolation = cv2.INTER_LINEAR)\n",
    "    print(imgScale.shape)\n",
    "#     cv2.imwrite('image_address/address.png', imgScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SEAMESE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
